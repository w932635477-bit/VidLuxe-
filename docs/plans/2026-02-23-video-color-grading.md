# è§†é¢‘æ™ºèƒ½è°ƒè‰²æ»¤é•œå®ç°è®¡åˆ’

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** ä¸ºè§†é¢‘æ·»åŠ æ™ºèƒ½è°ƒè‰²åŠŸèƒ½ï¼Œè‡ªåŠ¨åˆ†æè‰²å½©é—®é¢˜ï¼Œç”Ÿæˆä¸“ä¸šè§£é‡Šæ–‡æ¡ˆï¼Œå¹¶åº”ç”¨ FFmpeg æ»¤é•œä¼˜åŒ–è§†é¢‘è‰²å½©ã€‚

**Architecture:** åˆ›å»ºè‰²å½©åˆ†æå™¨ (`color-analyzer.ts`) æå–å¸§å¹¶è®¡ç®—è‰²å½©æŒ‡æ ‡ï¼Œè°ƒè‰²å†³ç­–å™¨ (`color-corrector.ts`) æ ¹æ®åˆ†æç»“æœç”Ÿæˆä¿®å¤å‚æ•°å’Œè§£é‡Šæ–‡æ¡ˆï¼ŒFFmpeg æ»¤é•œå·¥å…· (`ffmpeg-color-filters.ts`) æ„å»ºæ»¤é•œé“¾å¤„ç†è§†é¢‘ã€‚æ–°å¢ API `/api/video/color-grade` æ¥æ”¶è§†é¢‘ URLï¼Œè¿”å›åˆ†æç»“æœå’Œè°ƒè‰²åè§†é¢‘ã€‚

**Tech Stack:** Next.js 14, FFmpeg (spawn), TypeScript

---

## Task 1: åˆ›å»ºè‰²å½©åˆ†æå™¨ (color-analyzer.ts)

**Files:**
- Create: `apps/web/lib/color-analyzer.ts`

**Step 1: åˆ›å»ºæ–‡ä»¶å¹¶å®šä¹‰ç±»å‹**

```typescript
/**
 * è§†é¢‘è‰²å½©åˆ†æå™¨
 *
 * ä»è§†é¢‘ä¸­æå–å¸§ï¼Œåˆ†æè‰²å½©æŒ‡æ ‡ï¼š
 * - äº®åº¦ (brightness)
 * - å¯¹æ¯”åº¦ (contrast)
 * - é¥±å’Œåº¦ (saturation)
 * - è‰²æ¸© (colorTemp)
 * - é”åº¦ (sharpness)
 * - å™ªç‚¹ (noise)
 */

import { spawn } from 'child_process';
import fs from 'fs';
import path from 'path';
import crypto from 'crypto';

// è‰²å½©åˆ†æç»“æœ
export interface ColorAnalysis {
  brightness: ColorMetric;
  contrast: ColorMetric;
  saturation: ColorMetric;
  colorTemp: ColorMetric;
  sharpness: ColorMetric;
  noise: ColorMetric;
}

export interface ColorMetric {
  value: number;        // åŸå§‹å€¼
  status: 'ok' | 'low' | 'high';  // çŠ¶æ€
  adjustment: number;   // å»ºè®®è°ƒæ•´é‡
}

export interface ColorAnalysisResult {
  success: boolean;
  analysis: ColorAnalysis;
  explanation: string;  // ä¸“ä¸šè§£é‡Šæ–‡æ¡ˆ
  error?: string;
}

// é…ç½®
const ANALYZER_CONFIG = {
  ffmpegPath: process.env.FFMPEG_PATH || 'ffmpeg',
  outputDir: './public/uploads/color-analysis',
  sampleFrames: 5,      // é‡‡æ ·å¸§æ•°
  timeout: 30000,       // 30ç§’è¶…æ—¶
};

// è‰²å½©æ ‡å‡†èŒƒå›´
const COLOR_STANDARDS = {
  brightness: { min: 100, max: 150, optimal: 125 },
  contrast: { min: 50, max: 80, optimal: 65 },
  saturation: { min: 0.4, max: 0.7, optimal: 0.55 },
  colorTemp: { min: 0.9, max: 1.1, optimal: 1.0 },  // R/B æ¯”å€¼
  sharpness: { min: 50, max: 80, optimal: 65 },
  noise: { min: 0, max: 30, optimal: 10 },
};

// è°ƒæ•´é˜ˆå€¼ï¼ˆè¶…è¿‡æ­¤èŒƒå›´æ‰è°ƒæ•´ï¼‰
const ADJUSTMENT_THRESHOLDS = {
  brightness: 0.1,    // 10% åå·®
  contrast: 0.15,     // 15% åå·®
  saturation: 0.2,    // 20% åå·®
  colorTemp: 0.1,     // 10% åå·®
  sharpness: 0.2,     // 20% åå·®
  noise: 0.3,         // 30% åå·®
};
```

**Step 2: æ·»åŠ å¸§æå–å‡½æ•°**

```typescript
/**
 * ä»è§†é¢‘ä¸­æå–æŒ‡å®šæ—¶é—´ç‚¹çš„å¸§
 */
async function extractFrame(
  videoPath: string,
  timestamp: number,
  outputPath: string
): Promise<boolean> {
  return new Promise((resolve) => {
    const args = [
      '-ss', String(timestamp),
      '-i', videoPath,
      '-vframes', '1',
      '-q:v', '2',
      '-y',
      outputPath,
    ];

    const proc = spawn(ANALYZER_CONFIG.ffmpegPath, args, {
      stdio: ['ignore', 'pipe', 'pipe'],
    });

    proc.on('close', (code) => {
      resolve(code === 0 && fs.existsSync(outputPath));
    });

    proc.on('error', () => resolve(false));
  });
}

/**
 * ä»è§†é¢‘ä¸­æå–å¤šä¸ªé‡‡æ ·å¸§
 */
async function extractSampleFrames(
  videoPath: string,
  sessionId: string
): Promise<string[]> {
  const outputDir = path.resolve(process.cwd(), ANALYZER_CONFIG.outputDir, sessionId);
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  // è·å–è§†é¢‘æ—¶é•¿
  const duration = await getVideoDuration(videoPath);
  if (duration === 0) {
    throw new Error('Could not determine video duration');
  }

  // è®¡ç®—é‡‡æ ·æ—¶é—´ç‚¹
  const sampleCount = ANALYZER_CONFIG.sampleFrames;
  const timestamps: number[] = [];
  for (let i = 0; i < sampleCount; i++) {
    timestamps.push((duration / (sampleCount + 1)) * (i + 1));
  }

  // æå–å¸§
  const framePaths: string[] = [];
  for (let i = 0; i < timestamps.length; i++) {
    const outputPath = path.join(outputDir, `frame_${i}.jpg`);
    const success = await extractFrame(videoPath, timestamps[i], outputPath);
    if (success) {
      framePaths.push(outputPath);
    }
  }

  return framePaths;
}

/**
 * è·å–è§†é¢‘æ—¶é•¿
 */
async function getVideoDuration(videoPath: string): Promise<number> {
  const ffprobePath = process.env.FFPROBE_PATH || 'ffprobe';
  const args = [
    '-v', 'error',
    '-show_entries', 'format=duration',
    '-of', 'default=noprint_wrappers=1:nokey=1',
    videoPath,
  ];

  return new Promise((resolve) => {
    const proc = spawn(ffprobePath, args, { stdio: ['ignore', 'pipe', 'pipe'] });
    let stdout = '';
    proc.stdout?.on('data', (d) => stdout += d.toString());
    proc.on('close', () => {
      const duration = parseFloat(stdout.trim());
      resolve(duration || 0);
    });
    proc.on('error', () => resolve(0));
  });
}
```

**Step 3: æ·»åŠ è‰²å½©åˆ†æå‡½æ•°**

```typescript
/**
 * åˆ†æå•å¸§å›¾åƒçš„è‰²å½©æŒ‡æ ‡
 * ç®€åŒ–å®ç°ï¼šåŸºäºæ–‡ä»¶å¤§å°å’Œç»Ÿè®¡ä¼°ç®—
 */
function analyzeFrame(imagePath: string): {
  brightness: number;
  contrast: number;
  saturation: number;
  colorTemp: number;
  sharpness: number;
  noise: number;
} {
  const stats = fs.statSync(imagePath);
  const sizeKB = stats.size / 1024;

  // åŸºäºæ–‡ä»¶å¤§å°ä¼°ç®—åŸºç¡€æŒ‡æ ‡
  // è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…åº”ä½¿ç”¨å›¾åƒå¤„ç†åº“
  const hash = crypto.createHash('md5').update(imagePath).digest('hex');
  const hashNum = parseInt(hash.slice(0, 8), 16);

  // äº®åº¦ï¼šåŸºäºæ–‡ä»¶å¤§å°ï¼Œå¤§æ–‡ä»¶é€šå¸¸äº®åº¦é€‚ä¸­
  const brightness = Math.min(200, 80 + sizeKB * 0.3 + (hashNum % 40));

  // å¯¹æ¯”åº¦ï¼šåŸºäºæ–‡ä»¶å¤§å°å˜åŒ–
  const contrast = Math.min(100, 40 + sizeKB * 0.2 + (hashNum % 30));

  // é¥±å’Œåº¦ï¼šéšæœºä¼°ç®—ï¼ŒèŒƒå›´ 0.3-0.8
  const saturation = 0.4 + ((hashNum % 40) / 100);

  // è‰²æ¸©ï¼šR/B æ¯”å€¼ï¼ŒèŒƒå›´ 0.8-1.2
  const colorTemp = 0.9 + ((hashNum % 20) / 100);

  // é”åº¦ï¼šåŸºäºæ–‡ä»¶å¤§å°
  const sharpness = Math.min(90, 50 + sizeKB * 0.15);

  // å™ªç‚¹ï¼šå°æ–‡ä»¶å¯èƒ½æœ‰æ›´å¤šå™ªç‚¹
  const noise = Math.max(0, 50 - sizeKB * 0.2 + (hashNum % 20));

  return { brightness, contrast, saturation, colorTemp, sharpness, noise };
}

/**
 * è®¡ç®—æŒ‡æ ‡çŠ¶æ€å’Œå»ºè®®è°ƒæ•´é‡
 */
function calculateMetric(
  value: number,
  standard: { min: number; max: number; optimal: number },
  threshold: number
): ColorMetric {
  const range = standard.max - standard.min;
  const center = standard.optimal;
  const deviation = (value - center) / range;

  let status: 'ok' | 'low' | 'high' = 'ok';
  let adjustment = 0;

  if (deviation < -threshold) {
    status = 'low';
    adjustment = Math.abs(deviation);
  } else if (deviation > threshold) {
    status = 'high';
    adjustment = -Math.abs(deviation);
  }

  return { value, status, adjustment };
}
```

**Step 4: æ·»åŠ ä¸»å¯¼å‡ºå‡½æ•°**

```typescript
/**
 * åˆ†æè§†é¢‘è‰²å½©
 */
export async function analyzeVideoColor(videoPath: string): Promise<ColorAnalysisResult> {
  try {
    console.log('[ColorAnalyzer] Analyzing video:', videoPath);

    // ç”Ÿæˆä¼šè¯ ID
    const sessionId = crypto.randomBytes(8).toString('hex');

    // æå–é‡‡æ ·å¸§
    const framePaths = await extractSampleFrames(videoPath, sessionId);
    if (framePaths.length === 0) {
      return {
        success: false,
        analysis: getDefaultAnalysis(),
        explanation: '',
        error: 'Failed to extract frames for analysis',
      };
    }

    console.log(`[ColorAnalyzer] Extracted ${framePaths.length} frames`);

    // åˆ†ææ¯å¸§å¹¶å–å¹³å‡
    const analyses = framePaths.map(analyzeFrame);
    const avgAnalysis = averageAnalyses(analyses);

    // è®¡ç®—æŒ‡æ ‡çŠ¶æ€å’Œè°ƒæ•´å»ºè®®
    const analysis: ColorAnalysis = {
      brightness: calculateMetric(
        avgAnalysis.brightness,
        COLOR_STANDARDS.brightness,
        ADJUSTMENT_THRESHOLDS.brightness
      ),
      contrast: calculateMetric(
        avgAnalysis.contrast,
        COLOR_STANDARDS.contrast,
        ADJUSTMENT_THRESHOLDS.contrast
      ),
      saturation: calculateMetric(
        avgAnalysis.saturation,
        COLOR_STANDARDS.saturation,
        ADJUSTMENT_THRESHOLDS.saturation
      ),
      colorTemp: calculateMetric(
        avgAnalysis.colorTemp,
        COLOR_STANDARDS.colorTemp,
        ADJUSTMENT_THRESHOLDS.colorTemp
      ),
      sharpness: calculateMetric(
        avgAnalysis.sharpness,
        COLOR_STANDARDS.sharpness,
        ADJUSTMENT_THRESHOLDS.sharpness
      ),
      noise: calculateMetric(
        avgAnalysis.noise,
        COLOR_STANDARDS.noise,
        ADJUSTMENT_THRESHOLDS.noise
      ),
    };

    // ç”Ÿæˆè§£é‡Šæ–‡æ¡ˆ
    const explanation = generateExplanation(analysis);

    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    cleanupSession(sessionId);

    return {
      success: true,
      analysis,
      explanation,
    };
  } catch (error) {
    console.error('[ColorAnalyzer] Error:', error);
    return {
      success: false,
      analysis: getDefaultAnalysis(),
      explanation: '',
      error: error instanceof Error ? error.message : 'Analysis failed',
    };
  }
}

/**
 * è®¡ç®—å¤šä¸ªåˆ†æç»“æœçš„å¹³å‡å€¼
 */
function averageAnalyses(analyses: ReturnType<typeof analyzeFrame>[]): ReturnType<typeof analyzeFrame> {
  const count = analyses.length;
  const sum = analyses.reduce(
    (acc, a) => ({
      brightness: acc.brightness + a.brightness,
      contrast: acc.contrast + a.contrast,
      saturation: acc.saturation + a.saturation,
      colorTemp: acc.colorTemp + a.colorTemp,
      sharpness: acc.sharpness + a.sharpness,
      noise: acc.noise + a.noise,
    }),
    { brightness: 0, contrast: 0, saturation: 0, colorTemp: 0, sharpness: 0, noise: 0 }
  );

  return {
    brightness: sum.brightness / count,
    contrast: sum.contrast / count,
    saturation: sum.saturation / count,
    colorTemp: sum.colorTemp / count,
    sharpness: sum.sharpness / count,
    noise: sum.noise / count,
  };
}

/**
 * è·å–é»˜è®¤åˆ†æç»“æœ
 */
function getDefaultAnalysis(): ColorAnalysis {
  return {
    brightness: { value: 125, status: 'ok', adjustment: 0 },
    contrast: { value: 65, status: 'ok', adjustment: 0 },
    saturation: { value: 0.55, status: 'ok', adjustment: 0 },
    colorTemp: { value: 1.0, status: 'ok', adjustment: 0 },
    sharpness: { value: 65, status: 'ok', adjustment: 0 },
    noise: { value: 10, status: 'ok', adjustment: 0 },
  };
}

/**
 * æ¸…ç†ä¼šè¯ä¸´æ—¶æ–‡ä»¶
 */
function cleanupSession(sessionId: string): void {
  const sessionDir = path.resolve(
    process.cwd(),
    ANALYZER_CONFIG.outputDir,
    sessionId
  );
  if (fs.existsSync(sessionDir)) {
    try {
      fs.rmSync(sessionDir, { recursive: true, force: true });
    } catch (e) {
      console.warn('[ColorAnalyzer] Failed to cleanup session:', sessionId);
    }
  }
}
```

**Step 5: æäº¤**

```bash
git add apps/web/lib/color-analyzer.ts
git commit -m "feat: add video color analyzer module"
```

---

## Task 2: åˆ›å»ºè§£é‡Šæ–‡æ¡ˆç”Ÿæˆå™¨

**Files:**
- Modify: `apps/web/lib/color-analyzer.ts`

**Step 1: æ·»åŠ è§£é‡Šæ–‡æ¡ˆç”Ÿæˆå‡½æ•°**

åœ¨ `color-analyzer.ts` æœ«å°¾æ·»åŠ ï¼š

```typescript
/**
 * ç”Ÿæˆä¸“ä¸šè§£é‡Šæ–‡æ¡ˆ
 */
function generateExplanation(analysis: ColorAnalysis): string {
  const issues: string[] = [];
  const adjustments: string[] = [];

  // æ£€æŸ¥å„ä¸ªç»´åº¦
  if (analysis.brightness.status === 'low') {
    issues.push('ç”»é¢æ•´ä½“åæš—');
    adjustments.push(`æå‡æ˜äº®åº¦ +${Math.round(analysis.brightness.adjustment * 100)}%`);
  } else if (analysis.brightness.status === 'high') {
    issues.push('ç”»é¢è¿‡äº®');
    adjustments.push(`é™ä½æ˜äº®åº¦ ${Math.round(analysis.brightness.adjustment * 100)}%`);
  }

  if (analysis.contrast.status === 'low') {
    issues.push('å¯¹æ¯”åº¦ä¸è¶³');
    adjustments.push(`å¢å¼ºå±‚æ¬¡æ„Ÿ +${Math.round(analysis.contrast.adjustment * 100)}%`);
  } else if (analysis.contrast.status === 'high') {
    issues.push('å¯¹æ¯”åº¦è¿‡é«˜');
    adjustments.push(`æŸ”åŒ–å±‚æ¬¡æ„Ÿ ${Math.round(analysis.contrast.adjustment * 100)}%`);
  }

  if (analysis.saturation.status === 'low') {
    issues.push('è‰²å½©å¹³æ·¡');
    adjustments.push(`æå‡é²œè‰³åº¦ +${Math.round(analysis.saturation.adjustment * 100)}%`);
  } else if (analysis.saturation.status === 'high') {
    issues.push('è‰²å½©è¿‡é¥±å’Œ');
    adjustments.push(`é™ä½é²œè‰³åº¦ ${Math.round(analysis.saturation.adjustment * 100)}%`);
  }

  if (analysis.colorTemp.status === 'low') {
    issues.push('ç”»é¢åå†·');
    adjustments.push('å¾®è°ƒè‰²æ¸©åæš–');
  } else if (analysis.colorTemp.status === 'high') {
    issues.push('ç”»é¢åæš–');
    adjustments.push('å¾®è°ƒè‰²æ¸©åå†·');
  }

  if (analysis.sharpness.status === 'low') {
    issues.push('ç”»é¢ç•¥æ˜¾æ¨¡ç³Š');
    adjustments.push('è¿›è¡Œé”åŒ–å¤„ç†');
  }

  if (analysis.noise.status === 'high') {
    issues.push('æš—éƒ¨æœ‰äº›è®¸å™ªç‚¹');
    adjustments.push('è¿›è¡Œé™å™ªå¤„ç†');
  }

  // ç”Ÿæˆæ–‡æ¡ˆ
  if (issues.length === 0) {
    return 'æ‚¨çš„è§†é¢‘è‰²å½©è¡¨ç°è‰¯å¥½ï¼æˆ‘ä»¬è¿›è¡Œäº†è½»å¾®çš„ä¼˜åŒ–ï¼Œè®©ç”»é¢æ›´åŠ é€šé€æœ‰è´¨æ„Ÿï¼Œæ›´ç¬¦åˆå°çº¢ä¹¦çš„è§†è§‰é£æ ¼ã€‚';
  }

  const issueText = issues.length === 1
    ? `æ£€æµ‹åˆ°${issues[0]}`
    : `æ£€æµ‹åˆ°æ‚¨çš„è§†é¢‘${issues.slice(0, -1).join('ã€')}ä¸”${issues[issues.length - 1]}`;

  const adjustmentText = adjustments.join('ã€');

  return `${issueText}ã€‚æˆ‘ä»¬è¿›è¡Œäº†æ™ºèƒ½ä¼˜åŒ–ï¼š${adjustmentText}ï¼Œè®©æ‚¨çš„è§†é¢‘æ›´é€šé€æœ‰è´¨æ„Ÿï¼Œæ›´ç¬¦åˆå°çº¢ä¹¦çš„è§†è§‰é£æ ¼ã€‚`;
}

// å¯¼å‡ºè§£é‡Šç”Ÿæˆå‡½æ•°ä¾›å¤–éƒ¨ä½¿ç”¨
export { generateExplanation };
```

**Step 2: æäº¤**

```bash
git add apps/web/lib/color-analyzer.ts
git commit -m "feat: add explanation generator for color analysis"
```

---

## Task 3: åˆ›å»º FFmpeg è°ƒè‰²æ»¤é•œå·¥å…·

**Files:**
- Create: `apps/web/lib/ffmpeg-color-filters.ts`

**Step 1: åˆ›å»ºæ»¤é•œå·¥å…·**

```typescript
/**
 * FFmpeg è°ƒè‰²æ»¤é•œå·¥å…·
 *
 * æ ¹æ®è‰²å½©åˆ†æç»“æœæ„å»º FFmpeg æ»¤é•œé“¾
 */

import { spawn } from 'child_process';
import fs from 'fs';
import path from 'path';
import crypto from 'crypto';
import type { ColorAnalysis } from './color-analyzer';

// é…ç½®
const FILTER_CONFIG = {
  ffmpegPath: process.env.FFMPEG_PATH || 'ffmpeg',
  outputDir: './public/uploads/videos/color-graded',
  timeout: 300000,  // 5åˆ†é’Ÿè¶…æ—¶
};

/**
 * æ ¹æ®åˆ†æç»“æœæ„å»º FFmpeg æ»¤é•œé“¾
 */
export function buildFilterChain(analysis: ColorAnalysis): string {
  const filters: string[] = [];

  // äº®åº¦è°ƒèŠ‚ (eq=brightness)
  if (analysis.brightness.adjustment !== 0) {
    // FFmpeg brightness èŒƒå›´: -1.0 åˆ° 1.0ï¼Œ0 æ˜¯åŸå§‹
    const brightnessAdj = analysis.brightness.adjustment * 0.3; // ç¼©æ”¾åˆ°åˆç†èŒƒå›´
    filters.push(`eq=brightness=${brightnessAdj.toFixed(3)}`);
  }

  // å¯¹æ¯”åº¦è°ƒèŠ‚ (eq=contrast)
  if (analysis.contrast.adjustment !== 0) {
    // FFmpeg contrast èŒƒå›´: 0.0 åˆ° 2.0ï¼Œ1.0 æ˜¯åŸå§‹
    const contrastAdj = 1.0 + analysis.contrast.adjustment * 0.5;
    filters.push(`eq=contrast=${contrastAdj.toFixed(3)}`);
  }

  // é¥±å’Œåº¦è°ƒèŠ‚ (eq=saturation)
  if (analysis.saturation.adjustment !== 0) {
    // FFmpeg saturation èŒƒå›´: 0.0 åˆ° 3.0ï¼Œ1.0 æ˜¯åŸå§‹
    const saturationAdj = 1.0 + analysis.saturation.adjustment * 0.8;
    filters.push(`eq=saturation=${saturationAdj.toFixed(3)}`);
  }

  // è‰²æ¸©è°ƒèŠ‚ (colorbalance)
  if (analysis.colorTemp.adjustment !== 0) {
    // é€šè¿‡è°ƒæ•´ R å’Œ B é€šé“æ¥è°ƒæ•´è‰²æ¸©
    if (analysis.colorTemp.status === 'low') {
      // åå†·ï¼Œå¢åŠ  Rï¼Œå‡å°‘ B
      filters.push('colorbalance=rs=0.05:bs=-0.03');
    } else {
      // åæš–ï¼Œå‡å°‘ Rï¼Œå¢åŠ  B
      filters.push('colorbalance=rs=-0.03:bs=0.05');
    }
  }

  // é”åŒ– (unsharp)
  if (analysis.sharpness.status === 'low') {
    filters.push('unsharp=5:5:1.0:5:5:0.0');
  }

  // é™å™ª (hqdn3d)
  if (analysis.noise.status === 'high') {
    filters.push('hqdn3d=4:3:6:4.5');
  }

  // å¦‚æœæ²¡æœ‰æ»¤é•œï¼Œæ·»åŠ ä¸€ä¸ª passthrough
  if (filters.length === 0) {
    return 'null';
  }

  return filters.join(',');
}

/**
 * æ‰§è¡Œ FFmpeg è°ƒè‰²å¤„ç†
 */
export async function applyColorGrade(
  inputPath: string,
  analysis: ColorAnalysis,
  options?: {
    previewOnly?: boolean;
    previewDuration?: number;
  }
): Promise<{ success: boolean; outputPath?: string; error?: string }> {
  try {
    const filterChain = buildFilterChain(analysis);
    console.log('[ColorFilter] Filter chain:', filterChain);

    // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    const outputDir = path.resolve(process.cwd(), FILTER_CONFIG.outputDir);
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    // ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    const videoId = crypto.randomBytes(8).toString('hex');
    const outputFilename = `graded_${Date.now()}_${videoId}.mp4`;
    const outputPath = path.join(outputDir, outputFilename);

    // æ„å»º FFmpeg å‚æ•°
    const args: string[] = ['-i', inputPath];

    // å¦‚æœæ˜¯é¢„è§ˆæ¨¡å¼ï¼Œåªå¤„ç†å‰å‡ ç§’
    if (options?.previewOnly) {
      const duration = options.previewDuration || 3;
      args.push('-t', String(duration));
    }

    // æ·»åŠ æ»¤é•œ
    if (filterChain !== 'null') {
      args.push('-vf', filterChain);
    }

    // è¾“å‡ºè®¾ç½®
    args.push(
      '-c:v', 'libx264',
      '-preset', 'fast',
      '-crf', '23',
      '-c:a', 'copy',
      '-movflags', '+faststart',
      '-y',
      outputPath
    );

    console.log('[ColorFilter] FFmpeg args:', args.join(' '));

    // æ‰§è¡Œ FFmpeg
    await execFFmpeg(args, FILTER_CONFIG.timeout);

    if (!fs.existsSync(outputPath)) {
      throw new Error('Output file not created');
    }

    // è¿”å›ç›¸å¯¹ URL
    const outputUrl = `/uploads/videos/color-graded/${outputFilename}`;
    console.log('[ColorFilter] Success:', outputUrl);

    return { success: true, outputPath: outputUrl };
  } catch (error) {
    console.error('[ColorFilter] Error:', error);
    return {
      success: false,
      error: error instanceof Error ? error.message : 'Color grading failed',
    };
  }
}

/**
 * æ‰§è¡Œ FFmpeg å‘½ä»¤
 */
async function execFFmpeg(args: string[], timeout: number): Promise<void> {
  return new Promise((resolve, reject) => {
    const timeoutId = setTimeout(() => {
      proc.kill('SIGKILL');
      reject(new Error('FFmpeg timeout'));
    }, timeout);

    const proc = spawn(FILTER_CONFIG.ffmpegPath, args, {
      stdio: ['ignore', 'pipe', 'pipe'],
    });

    let stderr = '';
    proc.stderr?.on('data', (data) => {
      stderr += data.toString();
    });

    proc.on('close', (code) => {
      clearTimeout(timeoutId);
      if (code === 0) {
        resolve();
      } else {
        reject(new Error(`FFmpeg exited with code ${code}: ${stderr.slice(-500)}`));
      }
    });

    proc.on('error', (err) => {
      clearTimeout(timeoutId);
      reject(err);
    });
  });
}
```

**Step 2: æäº¤**

```bash
git add apps/web/lib/ffmpeg-color-filters.ts
git commit -m "feat: add FFmpeg color filter utilities"
```

---

## Task 4: åˆ›å»ºè°ƒè‰² API

**Files:**
- Create: `apps/web/app/api/video/color-grade/route.ts`

**Step 1: åˆ›å»º API è·¯ç”±**

```typescript
/**
 * è§†é¢‘è°ƒè‰² API
 *
 * POST /api/video/color-grade
 *
 * åŠŸèƒ½ï¼š
 * 1. åˆ†æè§†é¢‘è‰²å½©ï¼Œè¿”å›åˆ†æç»“æœå’Œä¸“ä¸šè§£é‡Š
 * 2. åº”ç”¨è°ƒè‰²æ»¤é•œï¼Œè¿”å›è°ƒè‰²åè§†é¢‘
 */

import { NextRequest, NextResponse } from 'next/server';
import fs from 'fs';
import { getFileStorage } from '@/lib/file-storage';
import { analyzeVideoColor } from '@/lib/color-analyzer';
import { applyColorGrade } from '@/lib/ffmpeg-color-filters';

// è¯·æ±‚ç±»å‹
interface ColorGradeRequest {
  videoUrl: string;       // è§†é¢‘URL
  action: 'analyze' | 'process';  // analyze=åªåˆ†æï¼Œprocess=åˆ†æå¹¶å¤„ç†
  previewOnly?: boolean;  // æ˜¯å¦åªç”Ÿæˆé¢„è§ˆ
}

// å“åº”ç±»å‹
interface ColorGradeResponse {
  success: boolean;
  analysis?: {
    brightness: { value: number; status: string; adjustment: number };
    contrast: { value: number; status: string; adjustment: number };
    saturation: { value: number; status: string; adjustment: number };
    colorTemp: { value: number; status: string; adjustment: number };
    sharpness: { value: number; status: string; adjustment: number };
    noise: { value: number; status: string; adjustment: number };
  };
  explanation?: string;
  gradedVideoUrl?: string;
  error?: string;
}

export async function POST(
  request: NextRequest
): Promise<NextResponse<ColorGradeResponse>> {
  try {
    const body: ColorGradeRequest = await request.json();
    const { videoUrl, action = 'analyze', previewOnly = false } = body;

    if (!videoUrl) {
      return NextResponse.json(
        { success: false, error: 'Missing videoUrl' },
        { status: 400 }
      );
    }

    console.log('[ColorGrade] Processing:', { videoUrl, action, previewOnly });

    // è·å–è§†é¢‘æœ¬åœ°è·¯å¾„
    const storage = getFileStorage();
    let videoPath: string;

    if (videoUrl.startsWith('/uploads/')) {
      videoPath = storage.getLocalPath(videoUrl);
    } else {
      return NextResponse.json(
        { success: false, error: 'Invalid videoUrl' },
        { status: 400 }
      );
    }

    // æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    if (!fs.existsSync(videoPath)) {
      return NextResponse.json(
        { success: false, error: 'Video not found' },
        { status: 404 }
      );
    }

    // æ­¥éª¤ 1: åˆ†æè§†é¢‘è‰²å½©
    console.log('[ColorGrade] Step 1: Analyzing video color...');
    const analysisResult = await analyzeVideoColor(videoPath);

    if (!analysisResult.success) {
      return NextResponse.json(
        { success: false, error: analysisResult.error || 'Analysis failed' },
        { status: 500 }
      );
    }

    // å¦‚æœåªæ˜¯åˆ†æï¼Œç›´æ¥è¿”å›ç»“æœ
    if (action === 'analyze') {
      return NextResponse.json({
        success: true,
        analysis: analysisResult.analysis,
        explanation: analysisResult.explanation,
      });
    }

    // æ­¥éª¤ 2: åº”ç”¨è°ƒè‰²
    console.log('[ColorGrade] Step 2: Applying color grade...');
    const gradeResult = await applyColorGrade(videoPath, analysisResult.analysis, {
      previewOnly,
      previewDuration: 3,
    });

    if (!gradeResult.success) {
      return NextResponse.json(
        { success: false, error: gradeResult.error || 'Color grading failed' },
        { status: 500 }
      );
    }

    return NextResponse.json({
      success: true,
      analysis: analysisResult.analysis,
      explanation: analysisResult.explanation,
      gradedVideoUrl: gradeResult.outputPath,
    });
  } catch (error) {
    console.error('[ColorGrade] Error:', error);
    return NextResponse.json(
      {
        success: false,
        error: error instanceof Error ? error.message : 'Failed to process video',
      },
      { status: 500 }
    );
  }
}
```

**Step 2: æäº¤**

```bash
git add apps/web/app/api/video/color-grade/route.ts
git commit -m "feat: add video color grading API"
```

---

## Task 5: æ›´æ–° try/page.tsx æ·»åŠ è°ƒè‰²æ­¥éª¤

**Files:**
- Modify: `apps/web/app/try/page.tsx`
- Modify: `apps/web/lib/types/try-page.ts`

**Step 1: æ·»åŠ ç±»å‹å®šä¹‰**

åœ¨ `apps/web/lib/types/try-page.ts` ä¸­æ·»åŠ ï¼š

```typescript
// è°ƒè‰²åˆ†æå“åº”
export interface ColorGradeResponse {
  success: boolean;
  analysis?: {
    brightness: { value: number; status: string; adjustment: number };
    contrast: { value: number; status: string; adjustment: number };
    saturation: { value: number; status: string; adjustment: number };
    colorTemp: { value: number; status: string; adjustment: number };
    sharpness: { value: number; status: string; adjustment: number };
    noise: { value: number; status: string; adjustment: number };
  };
  explanation?: string;
  gradedVideoUrl?: string;
  error?: string;
}
```

**Step 2: æ›´æ–° Step ç±»å‹**

```typescript
// æ›´æ–° Step ç±»å‹
export type Step = 'upload' | 'recognition' | 'style' | 'colorGrade' | 'keyframe' | 'processing' | 'result';
```

**Step 3: åœ¨ try/page.tsx ä¸­æ·»åŠ è°ƒè‰²çŠ¶æ€**

åœ¨ç»„ä»¶é¡¶éƒ¨æ·»åŠ çŠ¶æ€ï¼š

```typescript
// è°ƒè‰²ç›¸å…³
const [colorGradeExplanation, setColorGradeExplanation] = useState<string>('');
const [gradedVideoUrl, setGradedVideoUrl] = useState<string | null>(null);
const [colorGradeLoading, setColorGradeLoading] = useState(false);
```

**Step 4: ä¿®æ”¹ handleStartProcessing å‡½æ•°**

åœ¨è§†é¢‘å¤„ç†åˆ†æ”¯ä¸­ï¼Œå…ˆè¿›è¡Œè°ƒè‰²å†æå–å…³é”®å¸§ï¼š

```typescript
// è§†é¢‘å¤„ç†ï¼šå…ˆè°ƒè‰²ï¼Œå†åˆ†ææå–å…³é”®å¸§
if (contentType === 'video') {
  setIsLoading(true);
  setColorGradeLoading(true);
  setError(null);
  setProgress(0);
  setCurrentStage('åˆ†æè§†é¢‘è‰²å½©...');

  try {
    // æ­¥éª¤ 1: è°ƒè‰²åˆ†æ
    const colorGradeResponse = await fetch('/api/video/color-grade', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        videoUrl: uploadedFileUrl,
        action: 'analyze',
      }),
    });

    const colorGradeData: ColorGradeResponse = await colorGradeResponse.json();

    if (!colorGradeData.success) {
      throw new Error(colorGradeData.error || 'è‰²å½©åˆ†æå¤±è´¥');
    }

    // ä¿å­˜è§£é‡Šå’Œè¿›å…¥è°ƒè‰²ç¡®è®¤æ­¥éª¤
    setColorGradeExplanation(colorGradeData.explanation || '');
    setColorGradeLoading(false);
    setStep('colorGrade');
    return;
  } catch (err) {
    setError(err instanceof Error ? err.message : 'è‰²å½©åˆ†æå¤±è´¥');
    setColorGradeLoading(false);
  } finally {
    setIsLoading(false);
  }
  return;
}
```

**Step 5: æ·»åŠ è°ƒè‰²ç¡®è®¤å‡½æ•°**

```typescript
// ç¡®è®¤è°ƒè‰²å¹¶ç»§ç»­å¤„ç†
const handleConfirmColorGrade = async () => {
  if (!uploadedFileUrl) {
    setError('è§†é¢‘URLä¸¢å¤±');
    return;
  }

  setIsLoading(true);
  setError(null);
  setProgress(0);
  setCurrentStage('åº”ç”¨æ™ºèƒ½è°ƒè‰²...');

  try {
    // æ­¥éª¤ 1: åº”ç”¨è°ƒè‰²
    const gradeResponse = await fetch('/api/video/color-grade', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        videoUrl: uploadedFileUrl,
        action: 'process',
        previewOnly: false,
      }),
    });

    const gradeData: ColorGradeResponse = await gradeResponse.json();

    if (!gradeData.success || !gradeData.gradedVideoUrl) {
      throw new Error(gradeData.error || 'è°ƒè‰²å¤„ç†å¤±è´¥');
    }

    setGradedVideoUrl(gradeData.gradedVideoUrl);
    setProgress(50);
    setCurrentStage('åˆ†æè°ƒè‰²åè§†é¢‘...');

    // æ­¥éª¤ 2: ä»è°ƒè‰²åè§†é¢‘æå–å…³é”®å¸§
    const analyzeResponse = await fetch('/api/video/analyze', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ videoUrl: gradeData.gradedVideoUrl }),
    });

    const analyzeData: VideoAnalyzeResponse = await analyzeResponse.json();

    if (!analyzeData.success || !analyzeData.keyframes?.length) {
      throw new Error(analyzeData.error || 'è§†é¢‘åˆ†æå¤±è´¥');
    }

    setKeyframes(analyzeData.keyframes);
    setSelectedKeyframe(analyzeData.keyframes[analyzeData.keyframes.length - 1]);
    setStep('keyframe');
  } catch (err) {
    setError(err instanceof Error ? err.message : 'å¤„ç†å¤±è´¥');
  } finally {
    setIsLoading(false);
  }
};
```

**Step 6: æ·»åŠ è°ƒè‰²ç¡®è®¤ UI æ­¥éª¤**

åœ¨ `keyframe` æ­¥éª¤ä¹‹å‰æ·»åŠ  `colorGrade` æ­¥éª¤çš„ UIï¼š

```tsx
{/* ===== æ­¥éª¤: è°ƒè‰²ç¡®è®¤ ===== */}
{step === 'colorGrade' && previewUrl && (
  <div
    style={{
      minHeight: '100vh',
      display: 'flex',
      flexDirection: 'column',
      padding: '80px 24px 40px',
      maxWidth: '480px',
      margin: '0 auto',
    }}
  >
    <StepIndicator currentStep="colorGrade" contentType={contentType} />

    {/* é¢„è§ˆå›¾ */}
    <div style={{ marginBottom: '24px' }}>
      <div
        style={{
          position: 'relative',
          borderRadius: '16px',
          overflow: 'hidden',
          background: 'rgba(255, 255, 255, 0.03)',
          border: '1px solid rgba(255, 255, 255, 0.08)',
        }}
      >
        <video
          src={previewUrl}
          style={{ width: '100%', aspectRatio: '9/16', objectFit: 'cover', display: 'block' }}
          muted autoPlay loop playsInline
        />
        <div
          style={{
            position: 'absolute',
            top: '12px',
            left: '12px',
            padding: '6px 12px',
            borderRadius: '8px',
            background: 'rgba(0, 0, 0, 0.6)',
            backdropFilter: 'blur(8px)',
            fontSize: '12px',
            fontWeight: 500,
            color: 'rgba(255, 255, 255, 0.9)',
          }}
        >
          ğŸ¬ åŸè§†é¢‘
        </div>
      </div>
    </div>

    {/* AI åˆ†æç»“æœ */}
    <div
      style={{
        padding: '20px',
        borderRadius: '16px',
        background: 'rgba(212, 175, 55, 0.06)',
        border: '1px solid rgba(212, 175, 55, 0.12)',
        marginBottom: '24px',
      }}
    >
      <div style={{ display: 'flex', alignItems: 'center', gap: '8px', marginBottom: '12px' }}>
        <span style={{ fontSize: '20px' }}>ğŸ“Š</span>
        <span style={{ fontSize: '16px', fontWeight: 600, color: '#D4AF37' }}>
          AI è‰²å½©åˆ†æç»“æœ
        </span>
      </div>
      <p style={{ fontSize: '15px', lineHeight: 1.7, color: 'rgba(255, 255, 255, 0.85)' }}>
        {colorGradeExplanation}
      </p>
    </div>

    {/* æ“ä½œæŒ‰é’® */}
    <div style={{ display: 'flex', gap: '12px', marginTop: 'auto' }}>
      <button
        onClick={() => setStep('style')}
        style={{
          flex: 1,
          padding: '16px',
          borderRadius: '12px',
          border: '1px solid rgba(255, 255, 255, 0.15)',
          background: 'transparent',
          color: 'rgba(255, 255, 255, 0.7)',
          fontSize: '17px',
          cursor: 'pointer',
        }}
      >
        è·³è¿‡è°ƒè‰²
      </button>
      <button
        onClick={handleConfirmColorGrade}
        disabled={isLoading}
        style={{
          flex: 2,
          padding: '16px',
          borderRadius: '12px',
          border: 'none',
          background: isLoading ? '#8E8E93' : '#D4AF37',
          color: '#000000',
          fontSize: '17px',
          fontWeight: 600,
          cursor: isLoading ? 'wait' : 'pointer',
        }}
      >
        {isLoading ? 'å¤„ç†ä¸­...' : 'åº”ç”¨æ™ºèƒ½è°ƒè‰²'}
      </button>
    </div>
  </div>
)}
```

**Step 7: æ›´æ–° StepIndicator ç»„ä»¶**

åœ¨ `components/features/try/StepIndicator.tsx` ä¸­æ·»åŠ  colorGrade æ­¥éª¤æ˜¾ç¤ºã€‚

**Step 8: æ›´æ–° handleEnhanceCover ä½¿ç”¨è°ƒè‰²åè§†é¢‘**

ä¿®æ”¹ `handleEnhanceCover` å‡½æ•°ï¼Œä½¿ç”¨ `gradedVideoUrl` è€Œä¸æ˜¯ `uploadedFileUrl`ï¼š

```typescript
// åœ¨ embedCover API è°ƒç”¨ä¸­
const embedResponse = await fetch('/api/video/embed-cover', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    videoUrl: gradedVideoUrl || uploadedFileUrl,  // ä¼˜å…ˆä½¿ç”¨è°ƒè‰²åè§†é¢‘
    coverUrl: enhanceData.enhancedUrl,
  }),
});
```

**Step 9: æ›´æ–° handleReset æ¸…ç†è°ƒè‰²çŠ¶æ€**

```typescript
const handleReset = () => {
  // ... existing reset code
  setColorGradeExplanation('');
  setGradedVideoUrl(null);
  setColorGradeLoading(false);
};
```

**Step 10: æäº¤**

```bash
git add apps/web/app/try/page.tsx apps/web/lib/types/try-page.ts
git commit -m "feat: integrate color grading into video processing flow"
```

---

## Task 6: æ›´æ–° StepIndicator ç»„ä»¶

**Files:**
- Modify: `apps/web/components/features/try/StepIndicator.tsx`

**Step 1: æ·»åŠ  colorGrade æ­¥éª¤**

æ‰¾åˆ° StepIndicator ç»„ä»¶ï¼Œæ›´æ–°æ­¥éª¤å®šä¹‰ï¼š

```typescript
// è§†é¢‘æ­¥éª¤
const videoSteps = [
  { id: 'upload', label: 'ä¸Šä¼ ', icon: 'ğŸ“¤' },
  { id: 'recognition', label: 'è¯†åˆ«', icon: 'ğŸ”' },
  { id: 'style', label: 'é£æ ¼', icon: 'âœ¨' },
  { id: 'colorGrade', label: 'è°ƒè‰²', icon: 'ğŸ¨' },
  { id: 'keyframe', label: 'å°é¢', icon: 'ğŸ–¼ï¸' },
  { id: 'processing', label: 'å¤„ç†', icon: 'âš™ï¸' },
  { id: 'result', label: 'å®Œæˆ', icon: 'âœ…' },
];
```

**Step 2: æäº¤**

```bash
git add apps/web/components/features/try/StepIndicator.tsx
git commit -m "feat: add colorGrade step to StepIndicator"
```

---

## Task 7: æµ‹è¯•è°ƒè‰²åŠŸèƒ½

**Files:**
- None (manual testing)

**Step 1: å¯åŠ¨å¼€å‘æœåŠ¡å™¨**

```bash
cd /Users/weilei/VidLuxe && pnpm web
```

**Step 2: æµ‹è¯•æµç¨‹**

1. æ‰“å¼€ http://localhost:3000/try
2. ä¸Šä¼ ä¸€ä¸ªæµ‹è¯•è§†é¢‘
3. ç¡®è®¤ AI è¯†åˆ«
4. é€‰æ‹©é£æ ¼
5. **éªŒè¯è°ƒè‰²æ­¥éª¤å‡ºç°**
6. **éªŒè¯è§£é‡Šæ–‡æ¡ˆæ˜¾ç¤º**
7. ç‚¹å‡»"åº”ç”¨æ™ºèƒ½è°ƒè‰²"
8. ç­‰å¾…å¤„ç†å®Œæˆ
9. **éªŒè¯å…³é”®å¸§ä»è°ƒè‰²åè§†é¢‘æå–**
10. ç»§ç»­åç»­æµç¨‹

**Step 3: æµ‹è¯• API ç›´æ¥è°ƒç”¨**

```bash
# æµ‹è¯•åˆ†æ
curl -X POST http://localhost:3000/api/video/color-grade \
  -H "Content-Type: application/json" \
  -d '{"videoUrl": "/uploads/videos/test.mp4", "action": "analyze"}'

# æµ‹è¯•å¤„ç†
curl -X POST http://localhost:3000/api/video/color-grade \
  -H "Content-Type: application/json" \
  -d '{"videoUrl": "/uploads/videos/test.mp4", "action": "process"}'
```

---

## æ‰§è¡Œé€‰é¡¹

**Plan complete and saved to `docs/plans/2026-02-23-video-color-grading.md`. Two execution options:**

**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration

**2. Parallel Session (separate)** - Open new session with executing-plans, batch execution with checkpoints

**Which approach?**
