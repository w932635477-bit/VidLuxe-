# VidLuxe AI å­¦ä¹ å¼•æ“

## æ¦‚è¿°

AI å­¦ä¹ å¼•æ“æ˜¯ VidLuxe é«˜çº§æ„Ÿå¼•æ“çš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼Œé‡‡ç”¨ **B-LoRA** ä½œä¸ºæ ¸å¿ƒé£æ ¼å­¦ä¹ æŠ€æœ¯ï¼Œå®ç°å•å›¾é£æ ¼å­¦ä¹ ä¸è¿ç§»ã€‚

> **æ¸è¿›å¼æ–¹æ¡ˆæ ¸å¿ƒ**ï¼šMVP é˜¶æ®µé‡‡ç”¨ B-LoRA + Nano Banana æ··åˆæ¶æ„ï¼Œæ ‡å‡†é˜¶æ®µé€æ­¥è¿‡æ¸¡åˆ°è‡ªå»º SDXLã€‚

---

## æ¸è¿›å¼æŠ€æœ¯æ–¹æ¡ˆ

### MVP é˜¶æ®µï¼ˆå½“å‰ï¼‰

```
é£æ ¼å­¦ä¹ ï¼šB-LoRAï¼ˆå•å›¾å­¦ä¹ ï¼‰â­ æ ¸å¿ƒæŠ€æœ¯
â”œâ”€ æ¥æºï¼šhttps://github.com/yardenfren1996/B-LoRA
â”œâ”€ ç‰¹ç‚¹ï¼šå•å¼ å‚è€ƒå›¾å³å¯å­¦ä¹ é£æ ¼
â”œâ”€ è®ºæ–‡ï¼šECCV 2024
â””â”€ é›†æˆï¼šComfyUI-B-LoRA èŠ‚ç‚¹

ç´ æç”Ÿæˆï¼šNano Banana API
â”œâ”€ å¿«é€Ÿç”Ÿæˆï¼Œæ— éœ€ GPU
â”œâ”€ æˆæœ¬å¯æ§
â””â”€ æ•ˆæœç¨³å®š

å·¥ä½œæµï¼š
ç”¨æˆ·ä¸Šä¼ å‚è€ƒå›¾ â†’ B-LoRA æå–é£æ ¼ â†’ é£æ ¼åµŒå…¥ â†’ Nano Banana ç”Ÿæˆ
```

### æ ‡å‡†é˜¶æ®µï¼ˆ3-6 æœˆåï¼‰

```
é£æ ¼å­¦ä¹ ï¼šB-LoRAï¼ˆä¿æŒï¼‰
ç´ æç”Ÿæˆï¼šSDXL + B-LoRAï¼ˆè‡ªéƒ¨ç½²ï¼Œæˆæœ¬é™ä½ 70%ï¼‰
è§†é¢‘é£æ ¼ï¼š+ AnimateDiffï¼ˆæ—¶åºä¸€è‡´æ€§ï¼‰
```

---

## B-LoRA æ ¸å¿ƒæ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ B-LoRAï¼Ÿ

```
B-LoRA = Block-wise Low-Rank Adaptation

æ ¸å¿ƒèƒ½åŠ›ï¼š
1. ä»å•å¼ å›¾ç‰‡å­¦ä¹ é£æ ¼
2. éšå¼åˆ†ç¦»é£æ ¼å’Œå†…å®¹
3. å¯å°†å­¦åˆ°çš„é£æ ¼åº”ç”¨åˆ°ä»»æ„å†…å®¹

æŠ€æœ¯åŸç†ï¼š
â”œâ”€ åŸºäº SDXL + LoRA
â”œâ”€ å‘ç°ä¸¤ä¸ªå…³é”®å—ï¼ˆB-LoRA blocksï¼‰
â”œâ”€ è”åˆè®­ç»ƒå®ç°é£æ ¼-å†…å®¹åˆ†ç¦»
â””â”€ ECCV 2024 è®ºæ–‡éªŒè¯
```

### B-LoRA vs åŸæ–¹æ¡ˆ

| ç»´åº¦ | åŸæ–¹æ¡ˆ (CLIP + NIMA) | B-LoRA |
|------|---------------------|--------|
| **å­¦ä¹ æ–¹å¼** | éœ€è¦å¤§é‡æ ·æœ¬åº“ | å•å¼ å›¾ç‰‡ |
| **é£æ ¼ç†è§£** | å‘é‡ç›¸ä¼¼åº¦ | æ·±åº¦ç‰¹å¾æå– |
| **è¿ç§»è´¨é‡** | â­â­â­ | â­â­â­â­â­ |
| **å®ç°å¤æ‚åº¦** | é«˜ï¼ˆæ•°æ®åº“+æ£€ç´¢ï¼‰ | ä½ï¼ˆæ¨¡å‹åŠ è½½ï¼‰ |
| **GPU éœ€æ±‚** | ä½ | ä¸­ï¼ˆæ¨ç†ï¼‰ |
| **æˆæœ¬** | API è´¹ç”¨ | æ¨ç†è´¹ç”¨ |

---

## æ¨¡å—è®¾è®¡

### MVP é˜¶æ®µæ¨¡å—ç»“æ„

```
packages/learning/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ blora/                    # B-LoRA æ ¸å¿ƒ ğŸ†•
â”‚   â”‚   â”œâ”€â”€ blora-loader.ts       # æ¨¡å‹åŠ è½½
â”‚   â”‚   â”œâ”€â”€ style-extractor.ts    # é£æ ¼æå–
â”‚   â”‚   â”œâ”€â”€ style-embedding.ts    # é£æ ¼åµŒå…¥
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ analyzer/                 # å†…å®¹åˆ†æ
â”‚   â”‚   â”œâ”€â”€ content-analyzer.ts
â”‚   â”‚   â””â”€â”€ keyword-extractor.ts
â”‚   â”‚
â”‚   â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ models/                       # æ¨¡å‹æ–‡ä»¶
â”‚   â””â”€â”€ blora/                    # B-LoRA æƒé‡
â”‚
â””â”€â”€ package.json
```

### æ ¸å¿ƒæ¨¡å—ï¼šBLoRALoader

```typescript
// packages/learning/src/blora/blora-loader.ts

/**
 * B-LoRA æ¨¡å‹åŠ è½½å™¨
 * å‚è€ƒï¼šhttps://github.com/yardenfren1996/B-LoRA
 */
export class BLoRALoader {
  private model: SDXLModel;
  private contentBLora: LoRAWeights;
  private styleBLora: LoRAWeights;

  /**
   * åŠ è½½ B-LoRA æ¨¡å‹
   * å¯é€‰æ–¹å¼ï¼š
   * 1. æœ¬åœ°åŠ è½½ï¼ˆéœ€è¦ GPUï¼‰
   * 2. Modal/Replicate æ‰˜ç®¡ï¼ˆæ¨è MVPï¼‰
   */
  async loadModel(options: {
    method: 'local' | 'modal' | 'replicate';
    modelPath?: string;
  }): Promise<void> {
    switch (options.method) {
      case 'local':
        // æœ¬åœ°åŠ è½½ SDXL + B-LoRA
        this.model = await loadSDXL();
        break;
      case 'modal':
        // Modal æ‰˜ç®¡
        this.model = new ModalClient('b-lora');
        break;
      case 'replicate':
        // Replicate API
        this.model = new ReplicateClient('b-lora');
        break;
    }
  }

  /**
   * ä»å•å¼ å›¾ç‰‡æå–é£æ ¼
   * è¿™æ˜¯ B-LoRA çš„æ ¸å¿ƒèƒ½åŠ›
   */
  async extractStyle(referenceImage: ImageData): Promise<StyleEmbedding> {
    // 1. åŠ è½½å‚è€ƒå›¾ç‰‡
    // 2. è®­ç»ƒ/æå– B-LoRA æƒé‡
    // 3. è¿”å›é£æ ¼åµŒå…¥

    const styleEmbedding = await this.model.extractStyle(referenceImage);

    return {
      id: generateId(),
      vector: styleEmbedding.vector,
      contentWeight: styleEmbedding.contentWeight,
      styleWeight: styleEmbedding.styleWeight,
      metadata: {
        sourceImage: referenceImage,
        extractedAt: new Date(),
      },
    };
  }
}
```

### æ ¸å¿ƒæ¨¡å—ï¼šStyleExtractor

```typescript
// packages/learning/src/blora/style-extractor.ts

export interface StyleEmbedding {
  id: string;
  vector: number[];
  contentWeight: number;   // å†…å®¹æƒé‡ (0-1)
  styleWeight: number;     // é£æ ¼æƒé‡ (0-1)
  metadata: {
    sourceImage: ImageData;
    extractedAt: Date;
  };
}

export class StyleExtractor {
  private loader: BLoRALoader;

  constructor(loader: BLoRALoader) {
    this.loader = loader;
  }

  /**
   * ä»å‚è€ƒå›¾æå–é«˜çº§æ„Ÿé£æ ¼
   * æ”¯æŒ 4 ç§é¢„è®¾é£æ ¼
   */
  async extractPremiumStyle(
    referenceImage: ImageData,
    styleType: PremiumStyle
  ): Promise<StyleEmbedding> {
    // æå–é£æ ¼åµŒå…¥
    const embedding = await this.loader.extractStyle(referenceImage);

    // æ ¹æ®é£æ ¼ç±»å‹è°ƒæ•´æƒé‡
    const adjusted = this.adjustWeightsForStyle(embedding, styleType);

    return adjusted;
  }

  /**
   * æ ¹æ®é¢„è®¾é£æ ¼è°ƒæ•´æƒé‡
   */
  private adjustWeightsForStyle(
    embedding: StyleEmbedding,
    style: PremiumStyle
  ): StyleEmbedding {
    const styleWeights: Record<PremiumStyle, { style: number; content: number }> = {
      minimal: { style: 0.7, content: 0.3 },
      warm_luxury: { style: 0.8, content: 0.2 },
      cool_professional: { style: 0.75, content: 0.25 },
      morandi: { style: 0.85, content: 0.15 },
    };

    const weights = styleWeights[style];
    return {
      ...embedding,
      styleWeight: weights.style,
      contentWeight: weights.content,
    };
  }
}
```

---

## ä¸ç”Ÿæˆå¼•æ“é›†æˆ

### MVP é˜¶æ®µå·¥ä½œæµ

```typescript
import { StyleExtractor } from '@vidluxe/learning';
import { NanoBananaGenerator, PromptBuilder } from '@vidluxe/generator';

async function generatePremiumVideo(input: {
  userVideo: Video;
  referenceImage: ImageData;  // ç”¨æˆ·é€‰æ‹©çš„é£æ ¼å‚è€ƒå›¾
  style: PremiumStyle;
}) {
  // 1. B-LoRA æå–é£æ ¼
  const styleExtractor = new StyleExtractor(bLoRALoader);
  const styleEmbedding = await styleExtractor.extractPremiumStyle(
    input.referenceImage,
    input.style
  );

  // 2. æ„å»º Prompt
  const promptBuilder = new PromptBuilder();
  const prompt = promptBuilder.build(styleEmbedding, input.style);

  // 3. Nano Banana ç”Ÿæˆç´ æ
  const generator = new NanoBananaGenerator();
  const assets = await generator.generate({
    prompt,
    count: { backgrounds: 3, textCards: 5 },
  });

  // 4. Remotion åˆæˆè§†é¢‘
  // ... è§ generator.md

  return { video, assets };
}
```
const assets = await generator.generate({
  style: styleMatch.reference,
  content: contentAnalysis,
  prompts: PREMIUM_PROMPTS.minimal,
});

// 3. åˆæˆï¼šRemotion æ¸²æŸ“
const video = await composer.render(assets);
```

---

## å‚è€ƒé¡¹ç›®

åŸºäº GitHub æœ€ä½³å®è·µï¼Œæˆ‘ä»¬å‚è€ƒä»¥ä¸‹å¼€æºé¡¹ç›®ï¼š

| é¡¹ç›® | Stars | ç”¨é€” | é‡‡çº³åº¦ |
|------|-------|------|--------|
| [idealo/image-quality-assessment](https://github.com/idealo/image-quality-assessment) | 2.8k | NIMA ç¾å­¦è¯„ä¼° | æ ¸å¿ƒä¾èµ– |
| [rom1504/clip-retrieval](https://github.com/rom1504/clip-retrieval) | 2k+ | CLIP ç‰¹å¾æå– | æ ¸å¿ƒä¾èµ– |
| [yardenfren1996/B-LoRA](https://github.com/yardenfren1996/B-LoRA) | - | å•å›¾é£æ ¼å­¦ä¹  | æ¨è |
| [seunghyuns98/VideoColorGrading](https://github.com/seunghyuns98/VideoColorGrading) | - | è§†é¢‘è°ƒè‰² LUT | å¤‡é€‰ |
| [milvus-io/milvus](https://github.com/milvus-io/milvus) | 30k+ | å‘é‡æ•°æ®åº“ | å¯é€‰ |

---

## æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„

```mermaid
graph TB
    subgraph "æ•°æ®å±‚"
        A[ä¼˜è´¨è§†é¢‘æ•°æ®é›†]
        B[é£æ ¼å‘é‡æ•°æ®åº“]
    end

    subgraph "è®­ç»ƒå±‚"
        C[DatasetCollector]
        D[FeatureExtractor]
        E[StyleVectorizer]
        F[AestheticScorer]
    end

    subgraph "æ¨ç†å±‚"
        G[StyleMatcher]
        H[StyleTransferEngine]
        I[EnhancementPipeline]
    end

    A --> C
    C --> D
    D --> E
    D --> F
    E --> B
    F --> B

    B --> G
    G --> H
    H --> I
```

### æ¨¡å—åˆ’åˆ†

```
packages/learning/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ collector/           # æ•°æ®æ”¶é›†
â”‚   â”‚   â”œâ”€â”€ dataset-collector.ts
â”‚   â”‚   â”œâ”€â”€ youtube-collector.ts
â”‚   â”‚   â””â”€â”€ manual-uploader.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ extractor/           # ç‰¹å¾æå–
â”‚   â”‚   â”œâ”€â”€ feature-extractor.ts
â”‚   â”‚   â”œâ”€â”€ clip-encoder.ts
â”‚   â”‚   â””â”€â”€ dino-encoder.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ scorer/              # ç¾å­¦è¯„ä¼°
â”‚   â”‚   â”œâ”€â”€ aesthetic-scorer.ts
â”‚   â”‚   â”œâ”€â”€ nima-model.ts
â”‚   â”‚   â””â”€â”€ score-aggregator.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ store/               # å‘é‡å­˜å‚¨
â”‚   â”‚   â”œâ”€â”€ vector-store.ts
â”‚   â”‚   â”œâ”€â”€ supabase-store.ts
â”‚   â”‚   â””â”€â”€ milvus-store.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ matcher/             # é£æ ¼åŒ¹é…
â”‚   â”‚   â”œâ”€â”€ style-matcher.ts
â”‚   â”‚   â”œâ”€â”€ similarity-search.ts
â”‚   â”‚   â””â”€â”€ ranking-engine.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ transfer/            # é£æ ¼è¿ç§»
â”‚   â”‚   â”œâ”€â”€ style-transfer.ts
â”‚   â”‚   â”œâ”€â”€ lora-adapter.ts
â”‚   â”‚   â”œâ”€â”€ lut-generator.ts
â”‚   â”‚   â””â”€â”€ color-grading.ts
â”‚   â”‚
â”‚   â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ models/                  # é¢„è®­ç»ƒæ¨¡å‹
â”‚   â”œâ”€â”€ nima/
â”‚   â”œâ”€â”€ clip/
â”‚   â””â”€â”€ blora/
â”‚
â””â”€â”€ package.json
```

---

## æ ¸å¿ƒæ¨¡å—è®¾è®¡

### 1. æ•°æ®æ”¶é›†å™¨ (DatasetCollector)

```typescript
// packages/learning/src/collector/dataset-collector.ts

export interface PremiumVideoSample {
  id: string;
  source: 'youtube' | 'vimeo' | 'manual';
  url: string;
  category: 'luxury' | 'fashion' | 'tech' | 'lifestyle';
  labels: {
    brand?: string;
    style: PremiumStyle;
    mood: string[];
    quality: number;  // äººå·¥æ ‡æ³¨ 1-10
  };
  metadata: {
    duration: number;
    resolution: { width: number; height: number };
    fps: number;
  };
  frames?: ImageData[];
}

export class DatasetCollector {
  /**
   * ä» YouTube æ”¶é›†ä¼˜è´¨è§†é¢‘
   * å‚è€ƒå“ç‰Œå®˜æ–¹é¢‘é“ï¼šApple, HermÃ¨s, Chanel, etc.
   */
  async collectFromYouTube(params: {
    channels: string[];
    keywords: string[];
    maxVideos: number;
  }): Promise<PremiumVideoSample[]> {
    // ä½¿ç”¨ YouTube Data API v3
  }

  /**
   * æ‰‹åŠ¨æ·»åŠ é«˜è´¨é‡æ ·æœ¬
   */
  async addManualSample(
    videoUrl: string,
    labels: Partial<PremiumVideoSample['labels']>
  ): Promise<PremiumVideoSample> {
    // ä¸‹è½½ã€æå–å¸§ã€å­˜å‚¨
  }

  /**
   * éªŒè¯æ ·æœ¬è´¨é‡
   */
  async validateSample(sample: PremiumVideoSample): Promise<boolean> {
    // æ£€æŸ¥åˆ†è¾¨ç‡ã€æ—¶é•¿ã€å†…å®¹è´¨é‡
  }
}
```

### 2. ç‰¹å¾æå–å™¨ (FeatureExtractor)

```typescript
// packages/learning/src/extractor/feature-extractor.ts

import { CLIPModel } from '@xenova/transformers';
// å‚è€ƒ: https://github.com/rom1504/clip-retrieval

export interface StyleEmbedding {
  id: string;
  vector: number[];           // 512 ç»´ CLIP å‘é‡
  colorVector: number[];      // è‰²å½©ç‰¹å¾
  compositionVector: number[]; // æ„å›¾ç‰¹å¾
  source: string;
  aestheticsScore: number;    // NIMA è¯„åˆ†
  metadata: Record<string, any>;
}

export class FeatureExtractor {
  private clipModel: CLIPModel;
  private initialized: boolean = false;

  async initialize(): Promise<void> {
    // åŠ è½½ CLIP æ¨¡å‹ (æµè§ˆå™¨: Transformers.js / æœåŠ¡ç«¯: Python CLIP)
    this.clipModel = await CLIPModel.fromPretrained(
      'Xenova/clip-vit-base-patch32'
    );
    this.initialized = true;
  }

  /**
   * ä»è§†é¢‘å¸§æå–é£æ ¼ç‰¹å¾
   */
  async extractFromFrames(frames: ImageData[]): Promise<StyleEmbedding> {
    if (!this.initialized) await this.initialize();

    const embeddings: number[][] = [];

    for (const frame of frames) {
      const tensor = this.preprocessFrame(frame);
      const embedding = await this.clipModel.get_image_features(tensor);
      embeddings.push(Array.from(embedding.data));
    }

    // èšåˆï¼šå–å¹³å‡ + æå–å…³é”®å¸§ç‰¹å¾
    const aggregated = this.aggregateEmbeddings(embeddings);

    return {
      id: generateId(),
      vector: aggregated.overall,
      colorVector: aggregated.color,
      compositionVector: aggregated.composition,
      source: 'extracted',
      aestheticsScore: 0, // ç”± AestheticScorer å¡«å……
      metadata: {
        frameCount: frames.length,
        extractedAt: new Date().toISOString(),
      },
    };
  }

  /**
   * å¤šç»´åº¦ç‰¹å¾æå–
   */
  async extractMultiDimensional(frames: ImageData[]): Promise<{
    overall: StyleEmbedding;
    color: ColorFeatures;
    composition: CompositionFeatures;
    texture: TextureFeatures;
  }> {
    return {
      overall: await this.extractFromFrames(frames),
      color: await this.extractColorFeatures(frames),
      composition: await this.extractCompositionFeatures(frames),
      texture: await this.extractTextureFeatures(frames),
    };
  }

  private aggregateEmbeddings(embeddings: number[][]): {
    overall: number[];
    color: number[];
    composition: number[];
  } {
    // å¹³å‡æ± åŒ–
    const overall = this.meanPool(embeddings);

    // é¢œè‰²ç‰¹å¾æå– (ç®€åŒ–ç‰ˆ)
    const color = this.extractColorVector(embeddings);

    // æ„å›¾ç‰¹å¾æå–
    const composition = this.extractCompositionVector(embeddings);

    return { overall, color, composition };
  }
}
```

### 3. ç¾å­¦è¯„åˆ†å™¨ (AestheticScorer)

```typescript
// packages/learning/src/scorer/aesthetic-scorer.ts

// å‚è€ƒ: https://github.com/idealo/image-quality-assessment
// NIMA: Neural Image Assessment

export interface AestheticScore {
  mean: number;           // å¹³å‡åˆ† (1-10)
  std: number;            // æ ‡å‡†å·®
  distribution: number[]; // 1-10 åˆ†å¸ƒæ¦‚ç‡
  grade: 'excellent' | 'good' | 'average' | 'poor';
}

export class AestheticScorer {
  private nimaModel: any;

  async initialize(): Promise<void> {
    // åŠ è½½ NIMA æ¨¡å‹
    // å¯é€‰ backbone: MobileNet, InceptionResNetV2, EfficientNet
    this.nimaModel = await this.loadNimaModel('mobilenet');
  }

  /**
   * è¯„ä¼°å•å¸§ç¾å­¦åˆ†æ•°
   */
  async scoreFrame(frame: ImageData): Promise<AestheticScore> {
    const tensor = this.preprocessForNIMA(frame);
    const distribution = await this.nimaModel.predict(tensor);

    const mean = this.calculateMean(distribution);
    const std = this.calculateStd(distribution);

    return {
      mean,
      std,
      distribution: Array.from(distribution),
      grade: this.getGrade(mean),
    };
  }

  /**
   * è¯„ä¼°è§†é¢‘æ•´ä½“ç¾å­¦åˆ†æ•°
   */
  async scoreVideo(frames: ImageData[]): Promise<AestheticScore> {
    const scores = await Promise.all(
      frames.map(f => this.scoreFrame(f))
    );

    // èšåˆç­–ç•¥ï¼šåŠ æƒå¹³å‡ï¼ˆå…³é”®å¸§æƒé‡æ›´é«˜ï¼‰
    const weights = this.calculateFrameWeights(frames.length);
    const mean = scores.reduce((sum, s, i) => sum + s.mean * weights[i], 0);

    return {
      mean,
      std: this.calculateStd(scores.map(s => s.mean)),
      distribution: this.aggregateDistributions(scores),
      grade: this.getGrade(mean),
    };
  }

  private getGrade(mean: number): AestheticScore['grade'] {
    if (mean >= 8) return 'excellent';
    if (mean >= 6) return 'good';
    if (mean >= 4) return 'average';
    return 'poor';
  }
}
```

### 4. å‘é‡å­˜å‚¨ (VectorStore)

```typescript
// packages/learning/src/store/vector-store.ts

// å‚è€ƒ: https://github.com/milvus-io/milvus
// å‚è€ƒ: Supabase pgvector

export interface StyleVector {
  id: string;
  embedding: number[];
  metadata: {
    source: string;
    category: string;
    style: PremiumStyle;
    brand?: string;
    aestheticsScore: number;
    thumbnailUrl: string;
    createdAt: Date;
  };
}

export class VectorStore {
  private supabase: SupabaseClient;

  constructor(config: { url: string; key: string }) {
    this.supabase = createClient(config.url, config.key);
  }

  /**
   * å­˜å‚¨é£æ ¼å‘é‡
   */
  async storeStyleVector(vector: StyleVector): Promise<void> {
    await this.supabase.from('style_vectors').insert({
      id: vector.id,
      embedding: vector.embedding,
      metadata: vector.metadata,
    });
  }

  /**
   * ç›¸ä¼¼åº¦æœç´¢
   */
  async findSimilarStyles(
    queryEmbedding: number[],
    options: {
      topK?: number;
      threshold?: number;
      style?: PremiumStyle;
      category?: string;
    } = {}
  ): Promise<StyleVector[]> {
    const { topK = 10, threshold = 0.7 } = options;

    // ä½¿ç”¨ pgvector çš„ä½™å¼¦ç›¸ä¼¼åº¦
    const { data } = await this.supabase.rpc('match_styles', {
      query_embedding: queryEmbedding,
      match_threshold: threshold,
      match_count: topK,
    });

    return data;
  }

  /**
   * æŒ‰é£æ ¼è¿‡æ»¤
   */
  async findByStyle(style: PremiumStyle): Promise<StyleVector[]> {
    const { data } = await this.supabase
      .from('style_vectors')
      .select('*')
      .eq('metadata->style', style);

    return data;
  }

  /**
   * è·å–é«˜è´¨é‡æ ·æœ¬
   */
  async getTopQualitySamples(limit: number = 100): Promise<StyleVector[]> {
    const { data } = await this.supabase
      .from('style_vectors')
      .select('*')
      .gte('metadata->aestheticsScore', 8)
      .order('metadata->aestheticsScore', { ascending: false })
      .limit(limit);

    return data;
  }
}
```

### 5. é£æ ¼åŒ¹é…å™¨ (StyleMatcher)

```typescript
// packages/learning/src/matcher/style-matcher.ts

export interface StyleMatch {
  reference: StyleVector;
  similarity: number;
  transferParams: TransferParams;
  suggestions: string[];
}

export interface TransferParams {
  // è‰²å½©è°ƒæ•´
  saturation: { from: number; to: number };
  contrast: { from: number; to: number };
  temperature: { from: number; to: number };
  highlights: number;
  shadows: number;

  // è‰²å½©æŸ¥æ‰¾è¡¨
  lutUrl?: string;

  // LoRA æƒé‡ï¼ˆå¯é€‰ï¼‰
  loraWeights?: {
    style: number;
    content: number;
  };

  // å…¶ä»–å‚æ•°
  colorPalette?: RGBColor[];
  intensity: number;
}

export class StyleMatcher {
  private featureExtractor: FeatureExtractor;
  private vectorStore: VectorStore;

  /**
   * ä¸ºç”¨æˆ·è§†é¢‘åŒ¹é…æœ€ä½³å‚è€ƒé£æ ¼
   */
  async match(
    userFrames: ImageData[],
    options: {
      targetStyle?: PremiumStyle;
      category?: string;
      topK?: number;
    } = {}
  ): Promise<StyleMatch> {
    // 1. æå–ç”¨æˆ·è§†é¢‘ç‰¹å¾
    const userEmbedding = await this.featureExtractor.extractFromFrames(userFrames);

    // 2. å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
    const candidates = await this.vectorStore.findSimilarStyles(
      userEmbedding.vector,
      {
        topK: options.topK ?? 20,
        style: options.targetStyle,
        category: options.category,
      }
    );

    // 3. æ’åºï¼šç»¼åˆè€ƒè™‘ç›¸ä¼¼åº¦å’Œç¾å­¦åˆ†æ•°
    const ranked = this.rankCandidates(candidates, userEmbedding);

    // 4. é€‰æ‹©æœ€ä½³åŒ¹é…
    const bestMatch = ranked[0];

    // 5. è®¡ç®—è¿ç§»å‚æ•°
    const transferParams = await this.calculateTransferParams(
      userEmbedding,
      bestMatch
    );

    return {
      reference: bestMatch,
      similarity: this.cosineSimilarity(userEmbedding.vector, bestMatch.embedding),
      transferParams,
      suggestions: this.generateSuggestions(transferParams),
    };
  }

  /**
   * è®¡ç®—é£æ ¼è¿ç§»å‚æ•°
   */
  private async calculateTransferParams(
    source: StyleEmbedding,
    target: StyleVector
  ): Promise<TransferParams> {
    // åˆ†ææºå’Œç›®æ ‡çš„ç‰¹å¾å·®å¼‚
    const sourceColor = await this.analyzeColorDistribution(source);
    const targetColor = await this.analyzeColorDistribution(target);

    return {
      saturation: {
        from: sourceColor.saturation,
        to: targetColor.saturation,
      },
      contrast: {
        from: sourceColor.contrast,
        to: targetColor.contrast,
      },
      temperature: {
        from: sourceColor.temperature,
        to: targetColor.temperature,
      },
      highlights: targetColor.highlights - sourceColor.highlights,
      shadows: targetColor.shadows - sourceColor.shadows,
      colorPalette: targetColor.dominantColors,
      intensity: 0.8, // é»˜è®¤å¼ºåº¦
    };
  }
}
```

### 6. é£æ ¼è¿ç§»å¼•æ“ (StyleTransferEngine)

```typescript
// packages/learning/src/transfer/style-transfer.ts

// å‚è€ƒ: https://github.com/yardenfren1996/B-LoRA
// å‚è€ƒ: https://github.com/seunghyuns98/VideoColorGrading

export type TransferMethod = 'lut' | 'lora' | 'hybrid';

export class StyleTransferEngine {
  private lutGenerator: LUTGenerator;
  private loraAdapter: LoRAAdapter;

  /**
   * æ‰§è¡Œé£æ ¼è¿ç§»
   */
  async transfer(
    frames: ImageData[],
    params: TransferParams,
    method: TransferMethod = 'lut'
  ): Promise<ImageData[]> {
    switch (method) {
      case 'lut':
        return this.transferWithLUT(frames, params);
      case 'lora':
        return this.transferWithLoRA(frames, params);
      case 'hybrid':
        return this.transferHybrid(frames, params);
    }
  }

  /**
   * æ–¹æ³•1: LUT (Look-Up Table) è¿ç§»
   * å¿«é€Ÿã€å¯è§£é‡Šã€é€‚åˆè‰²å½©è°ƒæ•´
   */
  private async transferWithLUT(
    frames: ImageData[],
    params: TransferParams
  ): Promise<ImageData[]> {
    // ç”Ÿæˆæˆ–åŠ è½½ LUT
    const lut = params.lutUrl
      ? await this.loadLUT(params.lutUrl)
      : await this.lutGenerator.generate(params);

    // åº”ç”¨ LUT åˆ°æ¯ä¸€å¸§
    return frames.map(frame => this.applyLUT(frame, lut));
  }

  /**
   * æ–¹æ³•2: B-LoRA è¿ç§»
   * é«˜è´¨é‡ã€ä»å•å›¾å­¦ä¹ é£æ ¼
   */
  private async transferWithLoRA(
    frames: ImageData[],
    params: TransferParams
  ): Promise<ImageData[]> {
    // åŠ è½½é¢„è®­ç»ƒçš„ B-LoRA æƒé‡
    const loraWeights = await this.loraAdapter.load(params.loraWeights);

    // å¯¹æ¯ä¸€å¸§åº”ç”¨é£æ ¼è¿ç§»
    const results: ImageData[] = [];
    for (const frame of frames) {
      const transferred = await this.loraAdapter.apply(frame, loraWeights, {
        styleWeight: params.loraWeights?.style ?? 0.8,
        contentWeight: params.loraWeights?.content ?? 0.5,
      });
      results.push(transferred);
    }

    return results;
  }

  /**
   * æ–¹æ³•3: æ··åˆè¿ç§»
   * LUT è‰²å½© + LoRA çº¹ç†
   */
  private async transferHybrid(
    frames: ImageData[],
    params: TransferParams
  ): Promise<ImageData[]> {
    // 1. å…ˆç”¨ LUT è°ƒæ•´è‰²å½©
    const colorCorrected = await this.transferWithLUT(frames, params);

    // 2. å†ç”¨ LoRA æ·»åŠ çº¹ç†/ç»†èŠ‚
    if (params.loraWeights) {
      return this.transferWithLoRA(colorCorrected, params);
    }

    return colorCorrected;
  }
}

/**
 * LUT ç”Ÿæˆå™¨
 * å‚è€ƒ: https://github.com/seunghyuns98/VideoColorGrading
 */
export class LUTGenerator {
  /**
   * æ ¹æ®è¿ç§»å‚æ•°ç”Ÿæˆ 3D LUT
   */
  async generate(params: TransferParams): Promise<LUT3D> {
    const size = 33; // 33x33x33 LUT
    const lut = new Float32Array(size * size * size * 3);

    // éå†æ‰€æœ‰é¢œè‰²å€¼
    for (let r = 0; r < size; r++) {
      for (let g = 0; g < size; g++) {
        for (let b = 0; b < size; b++) {
          const input = {
            r: r / (size - 1),
            g: g / (size - 1),
            b: b / (size - 1),
          };

          // åº”ç”¨å˜æ¢
          const output = this.applyColorTransform(input, params);

          const idx = (r * size * size + g * size + b) * 3;
          lut[idx] = output.r;
          lut[idx + 1] = output.g;
          lut[idx + 2] = output.b;
        }
      }
    }

    return { data: lut, size };
  }

  private applyColorTransform(
    input: { r: number; g: number; b: number },
    params: TransferParams
  ): { r: number; g: number; b: number } {
    let { r, g, b } = input;

    // 1. è‰²æ¸©è°ƒæ•´
    const tempFactor = params.temperature.to / params.temperature.from;
    r *= tempFactor;
    b /= tempFactor;

    // 2. é¥±å’Œåº¦è°ƒæ•´
    const gray = 0.299 * r + 0.587 * g + 0.114 * b;
    const satFactor = params.saturation.to / params.saturation.from;
    r = gray + (r - gray) * satFactor;
    g = gray + (g - gray) * satFactor;
    b = gray + (b - gray) * satFactor;

    // 3. å¯¹æ¯”åº¦è°ƒæ•´
    const contrastFactor = params.contrast.to / params.contrast.from;
    r = (r - 0.5) * contrastFactor + 0.5;
    g = (g - 0.5) * contrastFactor + 0.5;
    b = (b - 0.5) * contrastFactor + 0.5;

    // 4. é«˜å…‰/é˜´å½±
    const luminance = 0.299 * r + 0.587 * g + 0.114 * b;
    if (luminance > 0.5) {
      const highlightAdj = params.highlights * (luminance - 0.5) * 2;
      r += highlightAdj * 0.01;
      g += highlightAdj * 0.01;
      b += highlightAdj * 0.01;
    } else {
      const shadowAdj = params.shadows * (0.5 - luminance) * 2;
      r += shadowAdj * 0.01;
      g += shadowAdj * 0.01;
      b += shadowAdj * 0.01;
    }

    // Clamp
    return {
      r: Math.max(0, Math.min(1, r)),
      g: Math.max(0, Math.min(1, g)),
      b: Math.max(0, Math.min(1, b)),
    };
  }
}
```

---

## ä¸ç°æœ‰æ¨¡å—é›†æˆ

### æ›¿æ¢ç¡¬ç¼–ç è§„åˆ™

```typescript
// packages/core/src/analyzer/color-analyzer.ts (æ›´æ–°)

import { AestheticScorer, StyleMatcher } from '@vidluxe/learning';

export class ColorAnalyzerV2 {
  private aestheticScorer: AestheticScorer;
  private styleMatcher: StyleMatcher;

  async analyzeFrame(frame: ImageData): Promise<ColorAnalysis> {
    // ä½¿ç”¨ NIMA æ›¿ä»£ç¡¬ç¼–ç è¯„åˆ†
    const aestheticScore = await this.aestheticScorer.scoreFrame(frame);

    // åŸæœ‰çš„è‰²å½©åˆ†æä¿ç•™
    const colorMetrics = this.calculateColorMetrics(frame);

    // æ ¹æ®ç¾å­¦åˆ†æ•°è°ƒæ•´è¯„åˆ†
    const adjustedScore = this.adjustScoreByAesthetics(
      colorMetrics,
      aestheticScore
    );

    return {
      ...colorMetrics,
      premiumScore: adjustedScore,
      aestheticScore: aestheticScore.mean,
      issues: this.generateIssues(colorMetrics, aestheticScore),
      suggestions: await this.generateAISuggestions(colorMetrics),
    };
  }

  private async generateAISuggestions(
    metrics: ColorMetrics
  ): Promise<string[]> {
    // åŒ¹é…ä¼˜è´¨é£æ ¼ï¼Œç”Ÿæˆæ™ºèƒ½å»ºè®®
    const match = await this.styleMatcher.match([this.currentFrame]);

    return match.suggestions;
  }
}
```

### å¢å¼ºç®¡é“æ›´æ–°

```typescript
// packages/core/src/enhancer/index.ts (æ›´æ–°)

import { StyleTransferEngine, StyleMatcher } from '@vidluxe/learning';

export class EnhancementEngineV2 {
  private styleMatcher: StyleMatcher;
  private transferEngine: StyleTransferEngine;

  async enhance(
    frames: ImageData[],
    options: EnhancementOptions
  ): Promise<EnhancementResult> {
    // 1. AI é£æ ¼åŒ¹é…
    const styleMatch = await this.styleMatcher.match(frames, {
      targetStyle: options.style,
    });

    // 2. é£æ ¼è¿ç§»
    const enhancedFrames = await this.transferEngine.transfer(
      frames,
      styleMatch.transferParams,
      'hybrid'
    );

    // 3. åå¤„ç†
    const processed = await this.postProcess(enhancedFrames);

    return {
      success: true,
      output: processed,
      styleMatch,
      improvements: this.calculateImprovements(frames, processed),
    };
  }
}
```

---

## æ•°æ®åº“ Schema æ‰©å±•

```sql
-- é£æ ¼å‘é‡è¡¨
CREATE TABLE style_vectors (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  embedding vector(512),  -- CLIP å‘é‡
  color_vector vector(256),
  composition_vector vector(256),
  metadata JSONB NOT NULL,
  aesthetics_score FLOAT,
  created_at TIMESTAMP DEFAULT NOW()
);

-- åˆ›å»ºå‘é‡ç´¢å¼•
CREATE INDEX ON style_vectors
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- ç›¸ä¼¼åº¦æœç´¢å‡½æ•°
CREATE OR REPLACE FUNCTION match_styles(
  query_embedding vector(512),
  match_threshold FLOAT,
  match_count INT
)
RETURNS TABLE (
  id UUID,
  embedding vector(512),
  metadata JSONB,
  similarity FLOAT
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    sv.id,
    sv.embedding,
    sv.metadata,
    1 - (sv.embedding <=> query_embedding) AS similarity
  FROM style_vectors sv
  WHERE 1 - (sv.embedding <=> query_embedding) > match_threshold
  ORDER BY sv.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;
```

---

## ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´æµç¨‹

```typescript
import {
  DatasetCollector,
  FeatureExtractor,
  AestheticScorer,
  VectorStore,
  StyleMatcher,
  StyleTransferEngine,
} from '@vidluxe/learning';

// 1. åˆå§‹åŒ–ç»„ä»¶
const collector = new DatasetCollector();
const extractor = new FeatureExtractor();
const scorer = new AestheticScorer();
const store = new VectorStore(config);
const matcher = new StyleMatcher(extractor, store);
const transfer = new StyleTransferEngine();

// 2. æ”¶é›†å¹¶ç´¢å¼•ä¼˜è´¨æ ·æœ¬
const samples = await collector.collectFromYouTube({
  channels: ['Apple', 'Hermes', 'Chanel'],
  keywords: ['luxury commercial', 'premium ad'],
  maxVideos: 100,
});

for (const sample of samples) {
  const embedding = await extractor.extractFromFrames(sample.frames);
  const aestheticsScore = await scorer.scoreVideo(sample.frames);

  await store.storeStyleVector({
    id: sample.id,
    embedding: embedding.vector,
    metadata: {
      ...sample.labels,
      aestheticsScore: aestheticsScore.mean,
    },
  });
}

// 3. å¤„ç†ç”¨æˆ·è§†é¢‘
const userFrames = await extractVideoFrames(userVideo);

// åŒ¹é…é£æ ¼
const match = await matcher.match(userFrames, {
  targetStyle: 'minimal',
});

// è¿ç§»é£æ ¼
const enhanced = await transfer.transfer(
  userFrames,
  match.transferParams,
  'hybrid'
);

console.log(`åŒ¹é…ç›¸ä¼¼åº¦: ${match.similarity}`);
console.log(`å‚è€ƒé£æ ¼æ¥æº: ${match.reference.metadata.source}`);
```

---

## å®æ–½è·¯çº¿å›¾

### Phase 1: åŸºç¡€è®¾æ–½ (2 å‘¨)

- [ ] åˆ›å»º `@vidluxe/learning` åŒ…ç»“æ„
- [ ] é›†æˆ CLIP æ¨¡å‹ (Transformers.js)
- [ ] è®¾ç½® Supabase pgvector

### Phase 2: æ ¸å¿ƒåŠŸèƒ½ (3 å‘¨)

- [ ] å®ç° FeatureExtractor
- [ ] å®ç° AestheticScorer (NIMA)
- [ ] å®ç° VectorStore

### Phase 3: é£æ ¼è¿ç§» (3 å‘¨)

- [ ] å®ç° StyleMatcher
- [ ] å®ç° LUTGenerator
- [ ] é›†æˆåˆ°ç°æœ‰ EnhancementEngine

### Phase 4: é«˜çº§åŠŸèƒ½ (4 å‘¨)

- [ ] å®ç° B-LoRA é£æ ¼è¿ç§»
- [ ] æ•°æ®é›†æ”¶é›†è‡ªåŠ¨åŒ–
- [ ] æ€§èƒ½ä¼˜åŒ–

---

## ä¸‹ä¸€æ­¥

- [AI ç´ æç”Ÿæˆå¼•æ“](./generator.md) ğŸ†• - Nano Banana é›†æˆ
- [å®æ–½è¯„ä¼°æŠ¥å‘Š](../EVALUATION.md)
- [åˆ†æå¼•æ“](./analyzer.md)
- [å¢å¼ºå¼•æ“](./enhancer.md)
